{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-03-23T07:01:56.559127Z","iopub.status.busy":"2023-03-23T07:01:56.558219Z","iopub.status.idle":"2023-03-23T07:01:56.622219Z","shell.execute_reply":"2023-03-23T07:01:56.620322Z","shell.execute_reply.started":"2023-03-23T07:01:56.559074Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>width</th>\n","      <th>height</th>\n","      <th>class</th>\n","      <th>xmin</th>\n","      <th>ymin</th>\n","      <th>xmax</th>\n","      <th>ymax</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Tomato-leaf-bacterial-spot-20-_jpg.rf.7db1aab3...</td>\n","      <td>640</td>\n","      <td>640</td>\n","      <td>Tomato leaf baterial spot</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>320</td>\n","      <td>297</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Tomato-leaf-bacterial-spot-20-_jpg.rf.7db1aab3...</td>\n","      <td>640</td>\n","      <td>640</td>\n","      <td>Tomato leaf baterial spot</td>\n","      <td>0</td>\n","      <td>373</td>\n","      <td>319</td>\n","      <td>640</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Tomato-leaf-bacterial-spot-20-_jpg.rf.7db1aab3...</td>\n","      <td>640</td>\n","      <td>640</td>\n","      <td>Tomato leaf baterial spot</td>\n","      <td>321</td>\n","      <td>311</td>\n","      <td>602</td>\n","      <td>640</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Tomato-leaf-late-blight-15-_jpg.rf.7dcf2d8ae84...</td>\n","      <td>640</td>\n","      <td>640</td>\n","      <td>Tomato leaf late blight</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>638</td>\n","      <td>634</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>39tomato_early_blight_jpg.rf.7dfa2f4a98e65481d...</td>\n","      <td>640</td>\n","      <td>640</td>\n","      <td>EarlyBlight</td>\n","      <td>145</td>\n","      <td>275</td>\n","      <td>193</td>\n","      <td>354</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            filename  width  height  \\\n","0  Tomato-leaf-bacterial-spot-20-_jpg.rf.7db1aab3...    640     640   \n","1  Tomato-leaf-bacterial-spot-20-_jpg.rf.7db1aab3...    640     640   \n","2  Tomato-leaf-bacterial-spot-20-_jpg.rf.7db1aab3...    640     640   \n","3  Tomato-leaf-late-blight-15-_jpg.rf.7dcf2d8ae84...    640     640   \n","4  39tomato_early_blight_jpg.rf.7dfa2f4a98e65481d...    640     640   \n","\n","                       class  xmin  ymin  xmax  ymax  \n","0  Tomato leaf baterial spot     0     0   320   297  \n","1  Tomato leaf baterial spot     0   373   319   640  \n","2  Tomato leaf baterial spot   321   311   602   640  \n","3    Tomato leaf late blight     7     0   638   634  \n","4                EarlyBlight   145   275   193   354  "]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# Load the annotations from a CSV file\n","annotations_df = pd.read_csv('/kaggle/input/my-other-data/train/_annotations.csv')\n","annotations_df.head()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-03-23T05:53:14.293871Z","iopub.status.busy":"2023-03-23T05:53:14.292640Z","iopub.status.idle":"2023-03-23T06:57:43.063275Z","shell.execute_reply":"2023-03-23T06:57:43.062160Z","shell.execute_reply.started":"2023-03-23T05:53:14.293814Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 10284 validated image filenames belonging to 13 classes.\n","Found 2572 validated image filenames belonging to 13 classes.\n","Epoch 1/15\n","285/285 [==============================] - 278s 942ms/step - loss: 1.8599 - accuracy: 0.3864 - val_loss: 1.1555 - val_accuracy: 0.6264\n","Epoch 2/15\n","285/285 [==============================] - 259s 911ms/step - loss: 0.9616 - accuracy: 0.7142 - val_loss: 0.7259 - val_accuracy: 0.7817\n","Epoch 3/15\n","285/285 [==============================] - 259s 908ms/step - loss: 0.6330 - accuracy: 0.8129 - val_loss: 0.5410 - val_accuracy: 0.8650\n","Epoch 4/15\n","285/285 [==============================] - 254s 891ms/step - loss: 0.4804 - accuracy: 0.8505 - val_loss: 0.4792 - val_accuracy: 0.8584\n","Epoch 5/15\n","285/285 [==============================] - 256s 899ms/step - loss: 0.4083 - accuracy: 0.8733 - val_loss: 0.3514 - val_accuracy: 0.8959\n","Epoch 6/15\n","285/285 [==============================] - 264s 927ms/step - loss: 0.3437 - accuracy: 0.8855 - val_loss: 0.3516 - val_accuracy: 0.8908\n","Epoch 7/15\n","285/285 [==============================] - 256s 899ms/step - loss: 0.3044 - accuracy: 0.8990 - val_loss: 0.3054 - val_accuracy: 0.8912\n","Epoch 8/15\n","285/285 [==============================] - 253s 888ms/step - loss: 0.2776 - accuracy: 0.9073 - val_loss: 0.2760 - val_accuracy: 0.9006\n","Epoch 9/15\n","285/285 [==============================] - 252s 885ms/step - loss: 0.2668 - accuracy: 0.9087 - val_loss: 0.2807 - val_accuracy: 0.9010\n","Epoch 10/15\n","285/285 [==============================] - 257s 902ms/step - loss: 0.2469 - accuracy: 0.9136 - val_loss: 0.3218 - val_accuracy: 0.8881\n","Epoch 11/15\n","285/285 [==============================] - 246s 865ms/step - loss: 0.2405 - accuracy: 0.9129 - val_loss: 0.2756 - val_accuracy: 0.9100\n","Epoch 12/15\n","285/285 [==============================] - 244s 858ms/step - loss: 0.2281 - accuracy: 0.9153 - val_loss: 0.2958 - val_accuracy: 0.8995\n","Epoch 13/15\n","285/285 [==============================] - 243s 854ms/step - loss: 0.2305 - accuracy: 0.9131 - val_loss: 0.2999 - val_accuracy: 0.8912\n","Epoch 14/15\n","285/285 [==============================] - 250s 879ms/step - loss: 0.2201 - accuracy: 0.9138 - val_loss: 0.2391 - val_accuracy: 0.9022\n","Epoch 15/15\n","285/285 [==============================] - 254s 891ms/step - loss: 0.2149 - accuracy: 0.9149 - val_loss: 0.2794 - val_accuracy: 0.9018\n","72/72 [==============================] - 31s 432ms/step - loss: 0.2788 - accuracy: 0.9016\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","# Define the input shape of the images\n","img_width = 224\n","img_height = 224\n","input_shape = (img_width, img_height, 3)\n","\n","# Define the batch size\n","batch_size = 36\n","\n","# Load the annotations from a CSV file\n","annotations_df = pd.read_csv('/kaggle/input/my-other-data/train*  /_annotations.csv')\n","\n","# Split the dataset into train and validation sets\n","train_df, valid_df = train_test_split(annotations_df, test_size=0.2, random_state=None)\n","\n","# Create an instance of the ImageDataGenerator class to perform data augmentation\n","train_datagen = ImageDataGenerator(rescale=1./255,\n","                                   shear_range=0.2,\n","                                   zoom_range=0.2,\n","                                   horizontal_flip=True)\n","\n","# Load the training dataset using the flow_from_dataframe method\n","train_generator = train_datagen.flow_from_dataframe(\n","        dataframe=train_df,\n","        directory='/kaggle/input/my-other-data/train/',\n","        x_col='filename',\n","        y_col='class',\n","        target_size=(img_width, img_height),\n","        batch_size=batch_size,\n","        class_mode='categorical',\n","        interpolation='bicubic',\n","        shuffle=True,\n","        seed=123)\n","\n","# Create an instance of the ImageDataGenerator class for the validation dataset\n","valid_datagen = ImageDataGenerator(rescale=1./255)\n","# Load the validation dataset using the flow_from_dataframe method\n","valid_generator = valid_datagen.flow_from_dataframe(\n","        dataframe=valid_df,\n","        directory='/kaggle/input/my-other-data/train/',\n","        x_col='filename',\n","        y_col='class',\n","        target_size=(img_width, img_height),\n","        batch_size=batch_size,\n","        class_mode='categorical',\n","        interpolation='bicubic',\n","        shuffle=True,\n","        seed=123)\n","\n","# Define the CNN model architecture\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=input_shape),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","      tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dense(13, activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(\n","        train_generator,\n","        steps_per_epoch=train_generator.samples // batch_size,\n","        epochs=15,\n","        validation_data=valid_generator,\n","        validation_steps=valid_generator.samples // batch_size,\n","        workers=tf.data.AUTOTUNE,\n","        use_multiprocessing=True)\n","\n","# Evaluate the model\n","model.evaluate(valid_generator)\n","model.save(\"my_model.h5\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-03-23T06:58:32.922108Z","iopub.status.busy":"2023-03-23T06:58:32.921746Z","iopub.status.idle":"2023-03-23T06:58:33.135724Z","shell.execute_reply":"2023-03-23T06:58:33.134758Z","shell.execute_reply.started":"2023-03-23T06:58:32.922076Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(None, 224, 224, 3)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["loaded_model = tf.keras.models.load_model('/kaggle/working/my_model.h5')\n","loaded_model.layers[0].input_shape #(None, 160, 160, 3)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-03-23T06:59:04.781947Z","iopub.status.busy":"2023-03-23T06:59:04.781231Z","iopub.status.idle":"2023-03-23T06:59:07.342171Z","shell.execute_reply":"2023-03-23T06:59:07.341161Z","shell.execute_reply.started":"2023-03-23T06:59:04.781911Z"},"trusted":true},"outputs":[{"data":{"text/plain":["22256940"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["import tensorflow as tf\n","\n","model = tf.keras.models.load_model('/kaggle/working/my_model.h5')\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","open(\"another_model.tflite\", \"wb\").write(tflite_model)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-03-23T07:00:36.182261Z","iopub.status.busy":"2023-03-23T07:00:36.181882Z","iopub.status.idle":"2023-03-23T07:00:36.217429Z","shell.execute_reply":"2023-03-23T07:00:36.216079Z","shell.execute_reply.started":"2023-03-23T07:00:36.182228Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","\n","interpreter = tf.lite.Interpreter(model_path='/kaggle/working/another_model.tflite')\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-03-23T07:01:19.796194Z","iopub.status.busy":"2023-03-23T07:01:19.795825Z","iopub.status.idle":"2023-03-23T07:01:20.213952Z","shell.execute_reply":"2023-03-23T07:01:20.212786Z","shell.execute_reply.started":"2023-03-23T07:01:19.796159Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 138ms/step\n","Predicted class index: 2\n","Predicted class probability: 48.65232706069946 \n"]}],"source":["from keras.models import load_model\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","import numpy as np\n","\n","# Load the model from the .h5 file\n","model = load_model('/kaggle/working/my_model.h5')\n","\n","# Load an example image\n","img_path = '/kaggle/input/my-keras-data/test/102Tomato_late_blight_jpg.rf.febbe89bbb4360f0788434dcf1d4c3c7.jpg'\n","img = load_img(img_path, target_size=(224, 224))\n","\n","# Preprocess the image\n","img_array = img_to_array(img)\n","img_array = np.expand_dims(img_array, axis=0)\n","img_array = img_array / 255.0\n","\n","# Make a prediction with the model\n","prediction = model.predict(img_array)\n","\n","# Print the predicted class and its probability\n","class_index = np.argmax(prediction)\n","class_prob = prediction[0, class_index]\n","print(f'Predicted class index: {class_index}')\n","print(f'Predicted class probability: {class_prob *100} ')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-22T09:46:27.622956Z","iopub.status.busy":"2023-03-22T09:46:27.622590Z","iopub.status.idle":"2023-03-22T09:46:34.283208Z","shell.execute_reply":"2023-03-22T09:46:34.282095Z","shell.execute_reply.started":"2023-03-22T09:46:27.622923Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","\n","model = tf.keras.models.load_model('/kaggle/working/my_model.h5')\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","open(\"another_model.tflite\", \"wb\").write(tflite_model)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
